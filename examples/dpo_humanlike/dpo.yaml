mode: train
global_config:
  total_epochs: 20
  batch_size: 32 # NOTE
model:
  model_path: '/PATH/TO/MODEL/CHECKPOINT/' # NOTE
  max_prompt_tokens: 1792
  max_response_tokens: 256
  checkpoint_path: 'checkpoints/trinity_dpo'
cluster:
  node_num: 1
  gpu_per_node: 8
buffer:
  max_retry_times: 3
  max_retry_interval: 1
  trainer_input:
    experience_buffer:
      name: dpo_buffer
      storage_type: file
      path: '/PATH/TO/DATASET/'
      format:
        prompt_type: plaintext # plaintext/messages/chatpair
        prompt_key: prompt
        chosen_key: chosen
        rejected_key: rejected
synchronizer:
  sync_method: 'checkpoint'
  sync_interval: 30
  sync_timeout: 1200
trainer:
  trainer_type: 'verl'
  algorithm_type: dpo
  trainer_config_path: 'examples/dpo_humanlike/train_dpo.yaml'
  save_interval: 30
monitor:
  cache_root_dir: ""
  project: "dpo_example"
  name: "trinity_dpo"
