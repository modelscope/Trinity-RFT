mode: both
global_config:
  total_epochs: 1
  batch_size: 4
  eval_interval: 1000
model:
  model_path: ''
  max_prompt_tokens: 2048
  max_response_tokens: 2048
  checkpoint_path: ''
cluster:  # 2 for explorer, 2 for trainer
  node_num: 1
  gpu_per_node: 4
buffer:
  max_retry_times: 3
  max_retry_interval: 1
  explorer_input:
    taskset:
      name: taskset
      storage_type: file
      path: ''
      split: 'train'
    default_workflow_type: ''
    default_reward_fn_type: ''
explorer:
  engine_type: vllm_async
  engine_num: 2
  runner_num: 4
  repeat_times: 1
  tensor_parallel_size: 1
  enable_prefix_caching: false
  enforce_eager: true
  dtype: bfloat16
  temperature: 1.0
  seed: 42
  logprobs: 0
  backend: nccl
  use_ray: false
  use_v1: true
trainer:
  trainer_type: verl
  trainer_config_path: tests/template/verl_config.yaml
  sft_warmup_steps: 0
  save_interval: 100
monitor:
  project: unittest
  name: test
synchronizer:
  sync_method: checkpoint
  sync_interval: 10
  sync_timeout: 1200
  wait_for_checkpoint: false
